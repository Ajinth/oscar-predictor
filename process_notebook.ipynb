{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Overview & motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our team members enjoy movies. In addition to enjoying movies, we also enjoy working with API’s and somewhat structured data sets. Therefore, determining what makes a movie successful using the data available in the Internet Movie Database (IMDB) and Wikipedia seemed like a natural choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import cPickle as pickle\n",
    "ia = IMDb(accessSystem='http')\n",
    "from collections import defaultdict \n",
    "import io\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "import sklearn.svm\n",
    "import math\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load AAdict (dict of Oscar nominated movies)\n",
    "AAdict = pickle.load(open('AAdict.p','rb'))\n",
    "# Load movies (dict of all movies)\n",
    "#movies = pickle.load(io.open('moviestemp.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nominated Best Actor</th>\n",
       "      <th>Nominated Best Actress</th>\n",
       "      <th>Nominated Best Animated Feature Film</th>\n",
       "      <th>Nominated Best Art Direction</th>\n",
       "      <th>Nominated Best Cinematography</th>\n",
       "      <th>Nominated Best Costume Design</th>\n",
       "      <th>Nominated Best Director</th>\n",
       "      <th>Nominated Best Documentary, Feature</th>\n",
       "      <th>Nominated Best Documentary, Short Subject</th>\n",
       "      <th>Nominated Best Film Editing</th>\n",
       "      <th>...</th>\n",
       "      <th>keywords</th>\n",
       "      <th>mpaa</th>\n",
       "      <th>nominations</th>\n",
       "      <th>releasedate</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "      <th>movieid</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0035423</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[time-travel, brooklyn-bridge, bridge, time-tr...</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>[Best Music, Song]</td>\n",
       "      <td>2001-12-25</td>\n",
       "      <td>118</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>[]</td>\n",
       "      <td>2001</td>\n",
       "      <td>0035423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0080388</th>\n",
       "      <td>Burt Lancaster</td>\n",
       "      <td>Susan Sarandon</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Louis Malle</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[drugs, gangster, camera-shot-of-feet, female-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Best Picture, Best Actor, Best Actress, Best ...</td>\n",
       "      <td>1981-04-03</td>\n",
       "      <td>104</td>\n",
       "      <td>Atlantic City</td>\n",
       "      <td>[]</td>\n",
       "      <td>1981</td>\n",
       "      <td>0080388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0080855</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tambi Larsen (Art Direction); Jim Berkey (Set ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[immigrant, sheriff, 1890s, johnson-county-war...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Best Art Direction]</td>\n",
       "      <td>1980-11-18</td>\n",
       "      <td>149</td>\n",
       "      <td>Heaven's Gate</td>\n",
       "      <td>[]</td>\n",
       "      <td>1981</td>\n",
       "      <td>0080855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0081974</th>\n",
       "      <td>Paul Newman</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[murder, newspaper, mafia, reporter, slander, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Best Actor, Best Supporting Actress, Best Wri...</td>\n",
       "      <td>1981-11-19</td>\n",
       "      <td>116</td>\n",
       "      <td>Absence of Malice</td>\n",
       "      <td>[]</td>\n",
       "      <td>1981</td>\n",
       "      <td>0081974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0081988</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Suzanne Bauman, Paul Neshamkin, Jim Burroughs ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Best Documentary, Feature]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>Against Wind and Tide: A Cuban Odyssey</td>\n",
       "      <td>[]</td>\n",
       "      <td>1981</td>\n",
       "      <td>0081988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Nominated Best Actor Nominated Best Actress  \\\n",
       "0035423                False                  False   \n",
       "0080388       Burt Lancaster         Susan Sarandon   \n",
       "0080855                False                  False   \n",
       "0081974          Paul Newman                  False   \n",
       "0081988                False                  False   \n",
       "\n",
       "        Nominated Best Animated Feature Film  \\\n",
       "0035423                                False   \n",
       "0080388                                False   \n",
       "0080855                                False   \n",
       "0081974                                False   \n",
       "0081988                                False   \n",
       "\n",
       "                              Nominated Best Art Direction  \\\n",
       "0035423                                              False   \n",
       "0080388                                              False   \n",
       "0080855  Tambi Larsen (Art Direction); Jim Berkey (Set ...   \n",
       "0081974                                              False   \n",
       "0081988                                              False   \n",
       "\n",
       "        Nominated Best Cinematography Nominated Best Costume Design  \\\n",
       "0035423                         False                         False   \n",
       "0080388                         False                         False   \n",
       "0080855                         False                         False   \n",
       "0081974                         False                         False   \n",
       "0081988                         False                         False   \n",
       "\n",
       "        Nominated Best Director  \\\n",
       "0035423                   False   \n",
       "0080388             Louis Malle   \n",
       "0080855                   False   \n",
       "0081974                   False   \n",
       "0081988                   False   \n",
       "\n",
       "                       Nominated Best Documentary, Feature  \\\n",
       "0035423                                              False   \n",
       "0080388                                              False   \n",
       "0080855                                              False   \n",
       "0081974                                              False   \n",
       "0081988  Suzanne Bauman, Paul Neshamkin, Jim Burroughs ...   \n",
       "\n",
       "        Nominated Best Documentary, Short Subject Nominated Best Film Editing  \\\n",
       "0035423                                     False                       False   \n",
       "0080388                                     False                       False   \n",
       "0080855                                     False                       False   \n",
       "0081974                                     False                       False   \n",
       "0081988                                     False                       False   \n",
       "\n",
       "         ...                                             keywords   mpaa  \\\n",
       "0035423  ...    [time-travel, brooklyn-bridge, bridge, time-tr...  PG-13   \n",
       "0080388  ...    [drugs, gangster, camera-shot-of-feet, female-...    NaN   \n",
       "0080855  ...    [immigrant, sheriff, 1890s, johnson-county-war...    NaN   \n",
       "0081974  ...    [murder, newspaper, mafia, reporter, slander, ...    NaN   \n",
       "0081988  ...                                                  NaN    NaN   \n",
       "\n",
       "                                               nominations releasedate  \\\n",
       "0035423                                 [Best Music, Song]  2001-12-25   \n",
       "0080388  [Best Picture, Best Actor, Best Actress, Best ...  1981-04-03   \n",
       "0080855                               [Best Art Direction]  1980-11-18   \n",
       "0081974  [Best Actor, Best Supporting Actress, Best Wri...  1981-11-19   \n",
       "0081988                        [Best Documentary, Feature]         NaN   \n",
       "\n",
       "        runtime                                   title won  year  movieid  \\\n",
       "0035423     118                          Kate & Leopold  []  2001  0035423   \n",
       "0080388     104                           Atlantic City  []  1981  0080388   \n",
       "0080855     149                           Heaven's Gate  []  1981  0080855   \n",
       "0081974     116                       Absence of Malice  []  1981  0081974   \n",
       "0081988      60  Against Wind and Tide: A Cuban Odyssey  []  1981  0081988   \n",
       "\n",
       "        winner  \n",
       "0035423      0  \n",
       "0080388      0  \n",
       "0080855      0  \n",
       "0081974      0  \n",
       "0081988      0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert AAdict to pandas\n",
    "AAdf = pd.DataFrame.from_dict(AAdict).transpose()\n",
    "AAdf['movieid'] = AAdf.index\n",
    "\n",
    "# Create new columns\n",
    "# number of nominations\n",
    "# winner\n",
    "AAdf['winner'] = AAdf['won'].apply(lambda x: len(x)!=0) * 1\n",
    "# convert years to ints\n",
    "AAdf['year'] = AAdf['year'].apply(lambda x: int(x))\n",
    "\n",
    "AAdf.head()\n",
    "#AAdf[AAdf['Nominated Best Actor']==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Star Power info to AAdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import and Split Data\n",
    "\n",
    "First we split our data into a validation set (movies in 2006) and a training set (movies 1981-2005).  We will use k-fold cross validation to train our model.  In this preliminary analysis, we train our model to predict Oscar winners given the movie was nominated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# convert release dates into quarters\n",
    "def get_quarter(monthint):\n",
    "    if len(monthint) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        if int(monthint[1]) <= 3:\n",
    "            return 1\n",
    "        if int(monthint[1]) >3 and int(monthint[1]) <=6:\n",
    "            return 2\n",
    "        if int(monthint[1]) >6 and int(monthint[1]) <=9:\n",
    "            return 3\n",
    "        if int(monthint[1]) >9:\n",
    "            return 4\n",
    "# convert release dates into month\n",
    "def get_month(monthint):\n",
    "    if len(monthint) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return(int(monthint[1]))\n",
    "\n",
    "# convert the string of countries into countries\n",
    "def get_countries(countrylist):\n",
    "    countries =[]\n",
    "    if countrylist == 0:\n",
    "        return [u'USA']\n",
    "    else:\n",
    "        for country in countrylist.split('/'):\n",
    "            country = country.replace(\" \", \"\")\n",
    "            countries.append(country)\n",
    "        return countries\n",
    "\n",
    "# Roc curve function, taken from HW3\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:#for stuff like logistic regression\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:#for stuff like SVM\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    if labe!=None:\n",
    "        for k in xrange(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Dealing with Categorical variables & creating other descriptive variables\n",
    "\n",
    "# mpaa is ordinal, convert to ordinal 'mpaaint'\n",
    "AAdf['mpaaint'] = AAdf['mpaa']\n",
    "AAdf['mpaaint'].loc[AAdf['mpaaint']=='R'] = 3\n",
    "AAdf['mpaaint'].loc[AAdf['mpaaint']=='PG-13'] = 2\n",
    "AAdf['mpaaint'].loc[AAdf['mpaaint']=='PG'] = 1\n",
    "AAdf['mpaaint'].loc[pd.isnull(AAdf['mpaaint'])] = 0\n",
    "\n",
    "# count number of nominations\n",
    "AAdf.loc[:,'numnominations'] = AAdf['nominations'].apply(lambda x: len(x))\n",
    "\n",
    "# convert release dates to quarters\n",
    "AAdf.loc[:,'quarter'] = AAdf['releasedate'].apply( lambda x: get_quarter(str(x).split('-')) )\n",
    "\n",
    "# convert release dates into months\n",
    "AAdf.loc[:,'month'] = AAdf['releasedate'].apply( lambda x: get_month(str(x).split('-')) )\n",
    "\n",
    "# convert release dates to number of days since beginning of the year\n",
    "AAdf.loc[:,'countrylist'] = AAdf['country'].apply( lambda x: get_countries(x) )\n",
    "# get unique list of countries\n",
    "allcountries = []\n",
    "for countrylist in AAdf['countrylist']:\n",
    "    for country in countrylist:\n",
    "        allcountries.append(country)\n",
    "uniquecountries = set(allcountries)\n",
    "# create dummy variables for countries\n",
    "for country in uniquecountries:\n",
    "    AAdf[country] = 0\n",
    "for movie in AAdf.iterrows():\n",
    "    if type(movie[1]['countrylist']) == list:\n",
    "        for country in uniquecountries:\n",
    "            if country in set(movie[1]['countrylist']):\n",
    "                AAdf.loc[movie[0],country] = 1\n",
    "            else:\n",
    "                AAdf.loc[movie[0],country] = 0\n",
    "\n",
    "# make genres into dummy variables\n",
    "\n",
    "AAdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                     u'Nominated Best Actor',\n",
       "                          u'Nominated Best Actress',\n",
       "            u'Nominated Best Animated Feature Film',\n",
       "                    u'Nominated Best Art Direction',\n",
       "                   u'Nominated Best Cinematography',\n",
       "                   u'Nominated Best Costume Design',\n",
       "                         u'Nominated Best Director',\n",
       "             u'Nominated Best Documentary, Feature',\n",
       "       u'Nominated Best Documentary, Short Subject',\n",
       "                     u'Nominated Best Film Editing', \n",
       "       ...\n",
       "                                           u'India',\n",
       "                 u'UnionofSovietSocialistRepublics',\n",
       "                                         u'Austria',\n",
       "                                         u'Vietnam',\n",
       "                                      u'Yugoslavia',\n",
       "                                              u'UK',\n",
       "                                         u'Hungary',\n",
       "                                          u'Taiwan',\n",
       "                                       u'Nicaragua',\n",
       "                       u'ThePalestinianTerritories'],\n",
       "      dtype='object', length=130)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split Data\n",
    "\n",
    "# Test Set:  will be 2006 movies\n",
    "testdf = AAdf[AAdf['year']>=2006].copy()\n",
    "\n",
    "# Training Set:  1981-2005 movies\n",
    "traindf = AAdf[AAdf['year']<2005].copy()\n",
    "\n",
    "# Create k-fold training/test datasets\n",
    "from sklearn.cross_validation import KFold\n",
    "kfdf = KFold(n=len(traindf), n_folds=10, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7324281150159744"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline classifier:\n",
    "1-np.mean(traindf['winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier\n",
    "\n",
    "Because the RandomForest Classifier can't take categorical variables as inputs.  Therefore we have to deal with the categorical variables in some way.\n",
    "\n",
    "For categorical variables that are considered ordinal (mpaa), we can just convert them to ints.\n",
    "For categorical varaibles that are not ordinal (keywords), we will use sparse matrcies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify desired variables to be used in the model\n",
    "#movievars=[u'runtime',u'year',u'releasedate',u'nominations',u'mpaa',u'genres',u'country']\n",
    "movievars=[u'runtime',u'year',u'mpaaint',u'numnominations',u'month']\n",
    "movievars.extend(list(uniquecountries))\n",
    "Xtrain=traindf[movievars].values\n",
    "Ytrain=traindf['winner'].values\n",
    "test=testdf[movievars].values\n",
    "\n",
    "#movievarstest = movievars\n",
    "#movievarstest.append(u'winner')\n",
    "xtest=testdf[movievars].values\n",
    "ytest=testdf['winner'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Random Forest classifier: 0.827586206897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Create the random forest object\n",
    "forest = RandomForestClassifier(n_estimators=1000, max_depth=15, min_samples_split=15, random_state=0)\n",
    "# Fit to the training data\n",
    "forest = forest.fit(Xtrain,Ytrain)\n",
    "# Predit on test data\n",
    "predictionRF = forest.predict(test)\n",
    "# Get score of prediction\n",
    "print \"Score of Random Forest classifier:\", forest.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(predictionRF, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "clfLR = lr.fit(Xtrain,Ytrain)\n",
    "predictionLR = lr.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.64172888,  0.35827112]), 0),\n",
       " (array([ 0.82709722,  0.17290278]), 0),\n",
       " (array([ 0.80466282,  0.19533718]), 0),\n",
       " (array([ 0.89524554,  0.10475446]), 0),\n",
       " (array([ 0.8907331,  0.1092669]), 0),\n",
       " (array([ 0.8688053,  0.1311947]), 1),\n",
       " (array([ 0.58910092,  0.41089908]), 1),\n",
       " (array([ 0.84974603,  0.15025397]), 0),\n",
       " (array([ 0.85724001,  0.14275999]), 0),\n",
       " (array([ 0.85311371,  0.14688629]), 0),\n",
       " (array([ 0.68059527,  0.31940473]), 0),\n",
       " (array([ 0.84420808,  0.15579192]), 1),\n",
       " (array([ 0.43056763,  0.56943237]), 1),\n",
       " (array([ 0.84386551,  0.15613449]), 0),\n",
       " (array([ 0.79058527,  0.20941473]), 0),\n",
       " (array([ 0.87020884,  0.12979116]), 1),\n",
       " (array([ 0.2480387,  0.7519613]), 1),\n",
       " (array([ 0.78266673,  0.21733327]), 1),\n",
       " (array([ 0.85724001,  0.14275999]), 0),\n",
       " (array([ 0.80369627,  0.19630373]), 0),\n",
       " (array([ 0.82033616,  0.17966384]), 0),\n",
       " (array([ 0.11532509,  0.88467491]), 1),\n",
       " (array([ 0.85405832,  0.14594168]), 0),\n",
       " (array([ 0.82688119,  0.17311881]), 0),\n",
       " (array([ 0.46894102,  0.53105898]), 1),\n",
       " (array([ 0.42162187,  0.57837813]), 0),\n",
       " (array([ 0.84438508,  0.15561492]), 0),\n",
       " (array([ 0.8668753,  0.1331247]), 0),\n",
       " (array([ 0.85724001,  0.14275999]), 1),\n",
       " (array([ 0.2155012,  0.7844988]), 1),\n",
       " (array([ 0.80700121,  0.19299879]), 0),\n",
       " (array([ 0.76879857,  0.23120143]), 0),\n",
       " (array([ 0.77768909,  0.22231091]), 0),\n",
       " (array([ 0.47206212,  0.52793788]), 0),\n",
       " (array([ 0.77893366,  0.22106634]), 0),\n",
       " (array([ 0.83589981,  0.16410019]), 0),\n",
       " (array([ 0.68981827,  0.31018173]), 0),\n",
       " (array([ 0.85360785,  0.14639215]), 0),\n",
       " (array([ 0.75270628,  0.24729372]), 0),\n",
       " (array([ 0.79918008,  0.20081992]), 0),\n",
       " (array([ 0.83402882,  0.16597118]), 0),\n",
       " (array([ 0.83271768,  0.16728232]), 0),\n",
       " (array([ 0.85909984,  0.14090016]), 0),\n",
       " (array([ 0.76157842,  0.23842158]), 1),\n",
       " (array([ 0.56010185,  0.43989815]), 1),\n",
       " (array([ 0.86915731,  0.13084269]), 0),\n",
       " (array([ 0.77497438,  0.22502562]), 0),\n",
       " (array([ 0.80943054,  0.19056946]), 1),\n",
       " (array([ 0.80168478,  0.19831522]), 0),\n",
       " (array([ 0.77742046,  0.22257954]), 0),\n",
       " (array([ 0.77398579,  0.22601421]), 1),\n",
       " (array([ 0.77368378,  0.22631622]), 0),\n",
       " (array([ 0.76366979,  0.23633021]), 0),\n",
       " (array([ 0.77145221,  0.22854779]), 0),\n",
       " (array([ 0.80282907,  0.19717093]), 0),\n",
       " (array([ 0.10024049,  0.89975951]), 1),\n",
       " (array([ 0.77616982,  0.22383018]), 0),\n",
       " (array([ 0.86155492,  0.13844508]), 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr.predict_proba?\n",
    "zip(predictionLR, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_roc() got an unexpected keyword argument 'prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0dc5d98ad4c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#with sns.hls_palette(8, l=.3, s=.8):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhls_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"logistic-regression\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclfLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#make_roc(\"logistic regression\",clfLR, ytest, xtest, labe=3, skip=50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: make_roc() got an unexpected keyword argument 'prob'"
     ]
    }
   ],
   "source": [
    "#with sns.hls_palette(8, l=.3, s=.8):\n",
    "with sns.hls_palette(8, l=.3, s=.8):\n",
    "    ax=make_roc(\"logistic-regression\",clfLR, ytest, xtest, labe=200, skip=50)\n",
    "#make_roc(\"logistic regression\",clfLR, ytest, xtest, labe=3, skip=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define do_classify and cv_optimize, used from homework 3.\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "    best = gs.best_estimator_\n",
    "    return best\n",
    "\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.3f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.3f\" % (test_accuracy)\n",
    "    print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1e-06}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Logistic Regresion and grid_search from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clfsvm=LinearSVC(loss=\"hinge\")\n",
    "Cs=[0.000001,0.00001,0.0001,0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "Xmatrix=traindf[movievars].values\n",
    "Yresp=traindf['winner'].values\n",
    "xtest=testdf[movievars].values\n",
    "ytest=testdf['winner'].values\n",
    "\n",
    "# Initialize classifer as Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Use GridSearchCV over the parameter grid of regularization coefficients in \n",
    "# the Cs array to get the best fit classifier using 5-fold cross validation\n",
    "fitmodel = GridSearchCV(clf, param_grid=dict(C=Cs), cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Fit over training data\n",
    "fitmodel.fit(Xmatrix,Yresp)\n",
    "\n",
    "# Find best value of C\n",
    "best = fitmodel.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.732428115016\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#calculate the accuracy here\n",
    "clf=LogisticRegression(C=fitmodel.best_params_['C'])\n",
    "clf.fit(Xmatrix,Yresp)\n",
    "ypred=clf.predict(Xmatrix)\n",
    "print \"Accuracy on training data: \", clf.score(Xmatrix, Yresp)\n",
    "#print \"Accuracy on test data: \", accuracy_score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-7dca8188a3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'from sklearn.svm import LinearSVC\\nfrom sklearn.grid_search import GridSearchCV\\nclfsvm, Xtrain, ytrain, Xtest, ytest = do_classify(LinearSVC(loss=\"hinge\"), {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, traindf, movievars, u\\'winner\\',1, mask=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2262\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-18cd86ef6e9e>\u001b[0m in \u001b[0;36mdo_classify\u001b[0;34m(clf, parameters, indf, featurenames, targetname, target1val, mask, reuse_split, score_func, n_folds)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-18cd86ef6e9e>\u001b[0m in \u001b[0;36mcv_optimize\u001b[0;34m(clf, parameters, X, y, n_folds, score_func)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"BEST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \"\"\"\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[0;32m/Users/Dana/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 120\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "clfsvm, Xtrain, ytrain, Xtest, ytest = do_classify(LinearSVC(loss=\"hinge\"), {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, traindf, movievars, u'winner',1, mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    4 ..., 1303 1304 1305]\n",
      "[   0    3   26   28   30   41   51   54   59   63   83   95  100  117  146\n",
      "  154  158  163  182  190  198  202  205  211  222  269  270  271  275  304\n",
      "  325  331  339  364  368  375  376  381  404  405  434  436  472  491  492\n",
      "  495  521  534  535  540  568  575  578  584  586  600  606  607  622  624\n",
      "  631  644  647  651  653  662  667  669  673  679  681  702  717  722  743\n",
      "  755  771  774  778  780  793  798  810  816  846  848  860  900  901  909\n",
      "  917  919  923  925  946  957  962  969  975  976  991 1000 1018 1035 1045\n",
      " 1063 1064 1092 1110 1112 1115 1118 1122 1125 1134 1149 1181 1197 1205 1210\n",
      " 1211 1218 1223 1227 1238 1259 1262 1276 1287 1292 1294]\n",
      "[   0    1    2 ..., 1303 1304 1305]\n",
      "[   7   12   60   77   81   92  114  122  126  131  153  161  173  174  196\n",
      "  204  248  249  255  268  287  296  308  312  318  320  327  342  345  349\n",
      "  357  383  393  400  401  406  408  413  418  423  439  440  443  449  458\n",
      "  507  526  528  542  550  555  560  602  608  628  632  637  649  664  665\n",
      "  671  698  704  707  711  733  744  747  763  770  775  828  831  835  836\n",
      "  838  839  852  872  878  882  908  924  932  938  940  953  961  967  973\n",
      "  985  987  988 1002 1008 1020 1023 1033 1061 1072 1073 1075 1086 1096 1104\n",
      " 1108 1109 1111 1116 1121 1135 1147 1150 1157 1165 1175 1183 1184 1188 1194\n",
      " 1196 1204 1206 1214 1235 1249 1261 1273 1286 1290 1295]\n",
      "[   0    1    3 ..., 1303 1304 1305]\n",
      "[   2   11   14   22   24   36   42   55   66   73  101  103  116  157  164\n",
      "  167  186  192  193  194  199  214  215  216  223  231  232  252  285  337\n",
      "  340  352  367  391  403  407  410  412  424  433  442  456  462  471  480\n",
      "  481  490  496  501  505  510  511  523  530  533  546  565  583  585  588\n",
      "  591  596  599  601  612  617  620  633  634  638  674  680  687  694  705\n",
      "  713  718  719  724  735  742  757  768  776  801  803  806  811  813  817\n",
      "  829  830  856  861  869  873  893  896  899  933  971  980  989  999 1001\n",
      " 1003 1005 1009 1012 1030 1037 1057 1065 1070 1078 1085 1098 1100 1124 1138\n",
      " 1163 1167 1177 1216 1236 1244 1251 1254 1256 1283 1291]\n",
      "[   0    1    2 ..., 1303 1304 1305]\n",
      "[   4   25   44   49   53   62   72   75   79   80   88   89  102  108  113\n",
      "  118  119  123  132  135  139  160  170  183  191  195  203  208  209  238\n",
      "  245  264  273  277  280  293  294  313  321  326  330  346  347  348  350\n",
      "  354  369  392  398  402  414  422  426  432  453  468  476  482  485  519\n",
      "  537  544  562  573  576  587  592  605  626  635  642  666  675  699  703\n",
      "  721  737  761  767  789  807  827  832  843  854  867  877  880  885  892\n",
      "  895  914  916  927  960  964  974  990 1004 1011 1025 1027 1029 1041 1047\n",
      " 1050 1054 1081 1103 1120 1126 1128 1133 1140 1142 1143 1148 1152 1156 1179\n",
      " 1198 1199 1224 1226 1233 1246 1253 1268 1278 1281 1296]\n",
      "[   0    1    2 ..., 1303 1304 1305]\n",
      "[  18   20   33   34   57   58   64   65   78   86   98  107  124  129  133\n",
      "  144  168  175  187  189  217  226  227  237  242  243  246  256  262  281\n",
      "  282  286  302  305  322  323  332  335  351  356  358  366  380  390  409\n",
      "  415  441  454  464  470  473  477  483  484  508  513  516  520  522  524\n",
      "  527  531  539  558  561  563  564  579  604  611  639  640  641  645  729\n",
      "  739  759  769  777  781  784  792  796  800  818  833  844  859  870  886\n",
      "  897  907  911  915  936  948  955  958  998 1015 1017 1022 1024 1032 1036\n",
      " 1038 1048 1049 1058 1062 1069 1091 1095 1123 1151 1153 1159 1164 1172 1190\n",
      " 1191 1192 1195 1215 1217 1219 1222 1250 1257 1267 1300]\n",
      "[   0    1    2 ..., 1302 1303 1305]\n",
      "[   6    8   15   16   21   39   40   56   67   71   85   99  104  105  106\n",
      "  112  130  140  143  151  155  165  184  188  197  200  201  228  233  236\n",
      "  251  257  258  266  267  274  276  292  300  311  314  353  365  387  395\n",
      "  396  425  428  437  445  451  460  466  493  500  502  506  509  512  514\n",
      "  532  545  547  556  557  572  574  580  610  623  627  636  655  659  668\n",
      "  676  682  690  701  706  716  720  725  750  760  766  786  795  809  814\n",
      "  842  862  863  898  906  913  922  931  934  935  937  949  952  965  983\n",
      "  993  995 1006 1013 1021 1084 1087 1101 1107 1132 1141 1154 1158 1161 1169\n",
      " 1170 1173 1185 1200 1203 1228 1247 1264 1272 1274 1304]\n",
      "[   0    1    2 ..., 1302 1304 1305]\n",
      "[  10   23   29   32   37   43   45   46   48   52   68   82   87   94   96\n",
      "  109  111  125  141  148  149  162  169  179  185  206  207  235  260  265\n",
      "  283  291  295  299  301  309  316  329  344  361  371  382  386  388  389\n",
      "  399  420  430  435  438  447  450  469  475  486  497  498  499  503  525\n",
      "  543  548  551  566  571  577  582  590  614  615  618  630  654  663  684\n",
      "  688  697  732  751  754  772  788  799  802  804  812  837  840  857  865\n",
      "  866  879  890  894  902  905  918  944  945  950  954  977  979  984  994\n",
      " 1010 1019 1034 1051 1055 1067 1099 1136 1160 1166 1168 1186 1193 1201 1208\n",
      " 1212 1213 1220 1234 1242 1265 1269 1284 1297 1303]\n",
      "[   0    1    2 ..., 1303 1304 1305]\n",
      "[  35   50   70   76   91   93  110  121  136  137  159  171  178  210  213\n",
      "  224  225  234  239  240  241  244  253  259  272  284  289  298  310  315\n",
      "  319  324  328  334  336  343  359  360  362  363  370  373  378  394  417\n",
      "  431  448  457  478  487  494  504  515  518  529  552  581  593  609  613\n",
      "  619  621  652  657  672  683  686  710  726  727  731  736  749  753  764\n",
      "  785  815  819  822  825  847  850  855  858  875  876  883  884  887  904\n",
      "  920  928  941  951  966  996  997 1014 1039 1043 1046 1056 1059 1066 1071\n",
      " 1076 1083 1089 1102 1105 1106 1127 1131 1137 1144 1162 1171 1176 1180 1189\n",
      " 1241 1258 1263 1266 1282 1285 1288 1293 1299 1301]\n",
      "[   0    1    2 ..., 1303 1304 1305]\n",
      "[   5   17   19   38   47   69   84  115  120  134  138  142  145  147  152\n",
      "  156  166  172  176  181  220  221  247  250  254  263  278  279  290  297\n",
      "  303  317  333  374  377  379  385  397  427  444  446  452  455  459  461\n",
      "  467  488  489  541  567  569  616  643  648  660  670  677  678  685  689\n",
      "  691  692  696  700  708  714  715  723  740  741  745  746  748  779  783\n",
      "  791  794  805  808  821  823  826  841  849  851  853  864  868  888  889\n",
      "  912  930  942  947  959  963  968  970  978  981  986 1026 1052 1060 1068\n",
      " 1079 1080 1082 1090 1094 1097 1117 1119 1146 1155 1187 1202 1209 1230 1231\n",
      " 1239 1248 1255 1260 1271 1275 1279 1280 1289 1298]\n",
      "[   0    2    3 ..., 1301 1303 1304]\n",
      "[   1    9   13   27   31   61   74   90   97  127  128  150  177  180  212\n",
      "  218  219  229  230  261  288  306  307  338  341  355  372  384  411  416\n",
      "  419  421  429  463  465  474  479  517  536  538  549  553  554  559  570\n",
      "  589  594  595  597  598  603  625  629  646  650  656  658  661  693  695\n",
      "  709  712  728  730  734  738  752  756  758  762  765  773  782  787  790\n",
      "  797  820  824  834  845  871  874  881  891  903  910  921  926  929  939\n",
      "  943  956  972  982  992 1007 1016 1028 1031 1040 1042 1044 1053 1074 1077\n",
      " 1088 1093 1113 1114 1129 1130 1139 1145 1174 1178 1182 1207 1221 1225 1229\n",
      " 1232 1237 1240 1243 1245 1252 1270 1277 1302 1305]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kfdf:\n",
    "    print train_index\n",
    "    print test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Logistic Regresion and grid_search from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Final Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
